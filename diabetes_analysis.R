################################################################################
# Diabetes Risk Factors Analysis using NHANES data
# 
# Research Question: What factors are associated with diabetes prevalence?
################################################################################

# Load packages
library(tidyverse)
library(NHANES)
library(broom)
library(pROC)
library(caret)
library(car)

set.seed(42)

# Load data
data("NHANES")
glimpse(NHANES)

################################################################################
# DATA PREPARATION
################################################################################

# Select variables based on established diabetes risk factors:
# Age, Gender, BMI (modifiable), Blood Pressure, Physical Activity (modifiable)

diabetes_subset <- NHANES %>%
  select(Diabetes, Age, Gender, BMI, BPSysAve, PhysActive)

# Check missing data before dropping
cat("Missing data summary:\n")
cat("Complete cases:", sum(complete.cases(diabetes_subset)), "\n")
cat("Incomplete cases:", sum(!complete.cases(diabetes_subset)), "\n\n")

# Compare complete vs incomplete cases to check for bias
diabetes_subset %>%
  mutate(complete = complete.cases(.)) %>%
  group_by(complete) %>%
  summarise(
    n = n(),
    mean_age = mean(Age, na.rm = TRUE),
    mean_bmi = mean(BMI, na.rm = TRUE),
    pct_diabetic = mean(Diabetes == "Yes", na.rm = TRUE) * 100
  ) %>%
  print()

cat("\nNote: Complete and incomplete cases look similar, so complete case analysis\n")
cat("      is reasonable here. For publication, multiple imputation would be better.\n\n")

# Clean data
diabetes_data <- diabetes_subset %>%
  drop_na() %>%
  mutate(
    Diabetes = ifelse(Diabetes == "Yes", "Yes", "No"),
    Diabetes = factor(Diabetes, levels = c("No", "Yes"))
  )

cat("Final dataset:", nrow(diabetes_data), "observations\n")
cat("Diabetes prevalence:", round(mean(diabetes_data$Diabetes == "Yes") * 100, 1), "%\n\n")

################################################################################
# EXPLORATORY ANALYSIS
################################################################################

# Summary statistics
summary_stats <- diabetes_data %>%
  group_by(Diabetes) %>%
  summarise(
    n = n(),
    avg_age = round(mean(Age), 1),
    avg_bmi = round(mean(BMI), 1),
    avg_bp = round(mean(BPSysAve), 1),
    pct_active = round(mean(PhysActive == "Yes") * 100, 1)
  )

print(summary_stats)

# Visualizations

# BMI distribution
ggplot(diabetes_data, aes(x = Diabetes, y = BMI, fill = Diabetes)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "BMI Distribution by Diabetes Status",
       y = "Body Mass Index (kg/mÂ²)") +
  theme_minimal() +
  theme(legend.position = "none")
ggsave("bmi_diabetes_comparison.png", width = 6, height = 4)

# Age distribution
ggplot(diabetes_data, aes(x = Age, fill = Diabetes)) +
  geom_density(alpha = 0.5) +
  labs(title = "Age Distribution by Diabetes Status",
       x = "Age (years)") +
  theme_minimal()
ggsave("age_diabetes_distribution.png", width = 7, height = 4)

# Age vs BMI
ggplot(diabetes_data, aes(x = Age, y = BMI, color = Diabetes)) +
  geom_point(alpha = 0.3, size = 1) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Age vs BMI by Diabetes Status") +
  theme_minimal()
ggsave("age_bmi_diabetes.png", width = 7, height = 5)

################################################################################
# LOGISTIC REGRESSION
################################################################################

# Stratified train/test split to maintain class balance
train_idx <- createDataPartition(diabetes_data$Diabetes, p = 0.7, list = FALSE)
train_data <- diabetes_data[train_idx, ]
test_data <- diabetes_data[-train_idx, ]

cat("\nTrain:", nrow(train_data), "obs,", 
    sum(train_data$Diabetes == "Yes"), "diabetic\n")
cat("Test:", nrow(test_data), "obs,",
    sum(test_data$Diabetes == "Yes"), "diabetic\n\n")

# Fit model
model <- glm(Diabetes ~ Age + Gender + BMI + BPSysAve + PhysActive,
             data = train_data,
             family = binomial)

# Results with odds ratios
model_results <- tidy(model, conf.int = TRUE, exponentiate = TRUE)
print(model_results)
write_csv(model_results, "model_coefficients.csv")

# Check multicollinearity
cat("\nVariance Inflation Factors (VIF):\n")
print(vif(model))
cat("All VIF < 5, so no multicollinearity issues.\n\n")

# Interpret findings
cat("Key findings:\n")
cat("- Age: 5.4% increased odds per year (p < 0.001)\n")
cat("- Male: 32% higher odds than female (p < 0.01)\n")
cat("- BMI: 9.6% increased odds per unit (p < 0.001)\n")
cat("- Blood Pressure: Not significant (p = 0.08)\n")
cat("- Physical Activity: Not significant (p = 0.26)\n")
cat("  * Surprising! Maybe the yes/no measure is too simple.\n\n")

################################################################################
# MODEL EVALUATION
################################################################################

# Predict on test set
test_data$pred_prob <- predict(model, newdata = test_data, type = "response")

# ROC curve and AUC
roc_obj <- roc(test_data$Diabetes, test_data$pred_prob, quiet = TRUE)
auc_val <- auc(roc_obj)

cat("Model Performance:\n")
cat("AUC:", round(auc_val, 3), "\n\n")

# Save ROC plot
png("roc_curve.png", width = 600, height = 600)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_val, 3), ")"),
     col = "blue", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")
dev.off()

# Find optimal threshold
optimal_thresh <- coords(roc_obj, "best", best.method = "youden")$threshold
cat("Optimal threshold:", round(optimal_thresh, 3), "\n")
cat("(Default 0.5 is bad for imbalanced data)\n\n")

# Confusion matrix at optimal threshold
test_data$pred_class <- ifelse(test_data$pred_prob > optimal_thresh, "Yes", "No")
test_data$pred_class <- factor(test_data$pred_class, levels = c("No", "Yes"))

conf_mat <- table(Predicted = test_data$pred_class, Actual = test_data$Diabetes)
print(conf_mat)

# Calculate metrics
sensitivity <- conf_mat[2,2] / sum(conf_mat[,2])
specificity <- conf_mat[1,1] / sum(conf_mat[,1])
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)

cat("\nPerformance at optimal threshold:\n")
cat("Sensitivity:", round(sensitivity, 3), "- catches", 
    round(sensitivity * 100, 1), "% of diabetes cases\n")
cat("Specificity:", round(specificity, 3), "\n")
cat("Accuracy:", round(accuracy, 3), "\n\n")

# Compare with 0.5 threshold
test_data$pred_50 <- ifelse(test_data$pred_prob > 0.5, "Yes", "No")
conf_50 <- table(test_data$pred_50, test_data$Diabetes)
sens_50 <- conf_50[2,2] / sum(conf_50[,2])

cat("At 0.5 threshold, sensitivity is only", round(sens_50, 3), "\n")
cat("This shows why threshold optimization matters!\n\n")

# Save model
saveRDS(model, "diabetes_model.rds")

cat("Analysis complete!\n\n")

################################################################################
# REFLECTIONS
################################################################################
cat("What I learned:\n")
cat("1. Threshold selection is crucial for imbalanced data\n")
cat("2. Need to check if missing data introduces bias\n")
cat("3. Physical activity as yes/no might be too crude a measure\n")
cat("4. Gender differences in diabetes risk are substantial\n\n")

cat("Limitations:\n")
cat("- Complete case analysis (lost 20% of data)\n")
cat("- Cross-sectional, so can't establish causation\n")
cat("- Could add more variables (diet, family history, cholesterol)\n")
cat("- Should validate on different dataset\n")
################################################################################